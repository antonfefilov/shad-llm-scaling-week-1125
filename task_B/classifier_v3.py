#!/usr/bin/env python3
"""
Advanced Binary Classification Pipeline for Task B
Multiple strategies for improving ROC-AUC: feature engineering, tuning, stacking
"""

import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import cross_val_score, StratifiedKFold
from sklearn.metrics import roc_auc_score
from sklearn.calibration import CalibratedClassifierCV
from sklearn.preprocessing import StandardScaler
import warnings
warnings.filterwarnings('ignore')

try:
    import xgboost as xgb
    HAS_XGB = True
except ImportError:
    HAS_XGB = False

try:
    import lightgbm as lgb
    HAS_LGB = True
except ImportError:
    HAS_LGB = False


def load_data():
    """Load training and test datasets"""
    print("Loading data...")
    train_df = pd.read_csv('train.csv')
    test_df = pd.read_csv('test.csv')
    print(f"Training: {train_df.shape}, Test: {test_df.shape}")
    print(f"Target distribution: {train_df['target'].value_counts(normalize=True).to_dict()}")
    return train_df, test_df


def create_advanced_features(df, is_train=True):
    """Create advanced features"""
    df = df.copy()

    # Encode categorical
    df['C'] = (df['C'] == '+').astype(int)

    # Handle missing values - create indicator + imputation
    if 'E' in df.columns:
        df['E_missing'] = df['E'].isnull().astype(int)
        median_E = df['E'].median() if is_train else 2.0
        df['E'] = df['E'].fillna(median_E)

    # Fill other missing values
    for col in df.columns:
        if df[col].isnull().sum() > 0:
            df[col] = df[col].fillna(df[col].median() if is_train else 0)

    # Feature engineering
    # 1. Interactions between important features
    df['A_E'] = df['A'] * df['E']
    df['A_G'] = df['A'] * df['G']
    df['A_H'] = df['A'] * df['H']
    df['E_G'] = df['E'] * df['G']
    df['E_H'] = df['E'] * df['H']
    df['G_H'] = df['G'] * df['H']

    # 2. Polynomial features for key variables
    df['A_squared'] = df['A'] ** 2
    df['G_squared'] = df['G'] ** 2
    df['H_squared'] = df['H'] ** 2
    df['I_squared'] = df['I'] ** 2

    # 3. Logarithmic transformations (add small constant to avoid log(0))
    df['log_A'] = np.log1p(df['A'])
    df['log_G'] = np.log1p(df['G'] + 10)  # G can be small
    df['log_I'] = np.log1p(df['I'] + 10)  # I can be negative

    # 4. Ratios
    df['A_D_ratio'] = df['A'] / (df['D'] + 0.001)
    df['G_I_ratio'] = df['G'] / (df['I'] + 10)
    df['H_I_ratio'] = df['H'] / (df['I'] + 10)

    # 5. Aggregations
    df['sum_GHI'] = df['G'] + df['H'] + df['I']
    df['mean_GHI'] = (df['G'] + df['H'] + df['I']) / 3

    # 6. Distance/magnitude features
    df['magnitude_HI'] = np.sqrt(df['H']**2 + df['I']**2)

    # 7. Binned features
    df['A_bin'] = pd.cut(df['A'], bins=5, labels=False)
    df['G_bin'] = pd.cut(df['G'], bins=5, labels=False)

    return df


def preprocess_data(train_df, test_df):
    """Preprocess with advanced feature engineering"""
    print("\nPreprocessing with advanced features...")

    X_train = train_df.drop('target', axis=1).copy()
    y_train = train_df['target'].copy()
    X_test = test_df.copy()

    # Create advanced features
    X_train = create_advanced_features(X_train, is_train=True)
    X_test = create_advanced_features(X_test, is_train=False)

    print(f"Features after engineering: {X_train.shape[1]}")
    print(f"Feature names: {list(X_train.columns[:20])}...")

    return X_train, y_train, X_test


def train_tuned_xgboost(X_train, y_train, n_splits=5):
    """Train XGBoost with better hyperparameters"""
    if not HAS_XGB:
        return None, 0.0

    print("\n" + "="*60)
    print("XGBoost with Tuned Hyperparameters")
    print("="*60)

    n_pos = y_train.sum()
    n_neg = len(y_train) - n_pos
    scale_pos_weight = n_neg / n_pos

    # Better hyperparameters found through tuning
    xgb_model = xgb.XGBClassifier(
        n_estimators=1000,
        max_depth=6,
        learning_rate=0.03,
        subsample=0.85,
        colsample_bytree=0.85,
        colsample_bylevel=0.85,
        scale_pos_weight=scale_pos_weight,
        min_child_weight=5,
        gamma=0.05,
        reg_alpha=0.5,
        reg_lambda=2.0,
        random_state=42,
        eval_metric='auc',
        use_label_encoder=False,
        tree_method='hist'
    )

    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)
    cv_scores = cross_val_score(xgb_model, X_train, y_train, cv=cv, scoring='roc_auc', n_jobs=-1)

    print(f"CV ROC-AUC: {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})")

    xgb_model.fit(X_train, y_train)
    train_proba = xgb_model.predict_proba(X_train)[:, 1]
    train_auc = roc_auc_score(y_train, train_proba)
    print(f"Train ROC-AUC: {train_auc:.4f}")

    return xgb_model, cv_scores.mean()


def train_tuned_lightgbm(X_train, y_train, n_splits=5):
    """Train LightGBM with better hyperparameters"""
    if not HAS_LGB:
        return None, 0.0

    print("\n" + "="*60)
    print("LightGBM with Tuned Hyperparameters")
    print("="*60)

    n_pos = y_train.sum()
    n_neg = len(y_train) - n_pos
    scale_pos_weight = n_neg / n_pos

    lgb_model = lgb.LGBMClassifier(
        n_estimators=1000,
        max_depth=6,
        learning_rate=0.03,
        num_leaves=40,
        subsample=0.85,
        colsample_bytree=0.85,
        scale_pos_weight=scale_pos_weight,
        min_child_samples=25,
        reg_alpha=0.5,
        reg_lambda=2.0,
        random_state=42,
        verbose=-1,
        metric='auc',
        feature_fraction=0.85,
        bagging_fraction=0.85,
        bagging_freq=5
    )

    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)
    cv_scores = cross_val_score(lgb_model, X_train, y_train, cv=cv, scoring='roc_auc', n_jobs=-1)

    print(f"CV ROC-AUC: {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})")

    lgb_model.fit(X_train, y_train)
    train_proba = lgb_model.predict_proba(X_train)[:, 1]
    train_auc = roc_auc_score(y_train, train_proba)
    print(f"Train ROC-AUC: {train_auc:.4f}")

    return lgb_model, cv_scores.mean()


def train_random_forest(X_train, y_train, n_splits=5):
    """Train Random Forest"""
    print("\n" + "="*60)
    print("Random Forest")
    print("="*60)

    rf_model = RandomForestClassifier(
        n_estimators=700,
        max_depth=20,
        min_samples_split=15,
        min_samples_leaf=5,
        max_features='sqrt',
        class_weight='balanced',
        random_state=42,
        n_jobs=-1
    )

    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)
    cv_scores = cross_val_score(rf_model, X_train, y_train, cv=cv, scoring='roc_auc', n_jobs=-1)

    print(f"CV ROC-AUC: {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})")

    rf_model.fit(X_train, y_train)
    train_proba = rf_model.predict_proba(X_train)[:, 1]
    train_auc = roc_auc_score(y_train, train_proba)
    print(f"Train ROC-AUC: {train_auc:.4f}")

    return rf_model, cv_scores.mean()


def train_gradient_boosting(X_train, y_train, n_splits=5):
    """Train Sklearn Gradient Boosting"""
    print("\n" + "="*60)
    print("Gradient Boosting")
    print("="*60)

    gb_model = GradientBoostingClassifier(
        n_estimators=500,
        learning_rate=0.05,
        max_depth=6,
        subsample=0.85,
        min_samples_split=20,
        min_samples_leaf=10,
        max_features='sqrt',
        random_state=42
    )

    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)
    cv_scores = cross_val_score(gb_model, X_train, y_train, cv=cv, scoring='roc_auc', n_jobs=-1)

    print(f"CV ROC-AUC: {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})")

    gb_model.fit(X_train, y_train)
    train_proba = gb_model.predict_proba(X_train)[:, 1]
    train_auc = roc_auc_score(y_train, train_proba)
    print(f"Train ROC-AUC: {train_auc:.4f}")

    return gb_model, cv_scores.mean()


def create_stacking_ensemble(base_models, X_train, y_train, n_splits=5):
    """Create stacking ensemble"""
    print("\n" + "="*60)
    print("Stacking Ensemble")
    print("="*60)

    estimators = [(name, model) for name, model in base_models.items()]

    # Use logistic regression as meta-learner
    stacking_model = StackingClassifier(
        estimators=estimators,
        final_estimator=LogisticRegression(
            C=0.1,
            max_iter=1000,
            random_state=42,
            class_weight='balanced'
        ),
        cv=5,
        n_jobs=-1
    )

    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)
    cv_scores = cross_val_score(stacking_model, X_train, y_train, cv=cv, scoring='roc_auc', n_jobs=-1)

    print(f"CV ROC-AUC: {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})")

    stacking_model.fit(X_train, y_train)
    train_proba = stacking_model.predict_proba(X_train)[:, 1]
    train_auc = roc_auc_score(y_train, train_proba)
    print(f"Train ROC-AUC: {train_auc:.4f}")

    return stacking_model, cv_scores.mean()


def calibrate_model(model, X_train, y_train, n_splits=5):
    """Calibrate model probabilities"""
    print("\nCalibrating probabilities...")

    calibrated = CalibratedClassifierCV(
        model,
        method='isotonic',
        cv=3
    )

    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)
    cv_scores = cross_val_score(calibrated, X_train, y_train, cv=cv, scoring='roc_auc', n_jobs=-1)

    print(f"Calibrated CV ROC-AUC: {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})")

    calibrated.fit(X_train, y_train)

    return calibrated, cv_scores.mean()


def main():
    """Main pipeline"""
    # Load data
    train_df, test_df = load_data()

    # Preprocess with advanced features
    X_train, y_train, X_test = preprocess_data(train_df, test_df)

    # Train multiple models
    models = {}
    scores = {}

    # Train base models
    rf_model, rf_score = train_random_forest(X_train, y_train)
    if rf_model is not None:
        models['RandomForest'] = rf_model
        scores['RandomForest'] = rf_score

    gb_model, gb_score = train_gradient_boosting(X_train, y_train)
    if gb_model is not None:
        models['GradientBoosting'] = gb_model
        scores['GradientBoosting'] = gb_score

    xgb_model, xgb_score = train_tuned_xgboost(X_train, y_train)
    if xgb_model is not None:
        models['XGBoost'] = xgb_model
        scores['XGBoost'] = xgb_score

    lgb_model, lgb_score = train_tuned_lightgbm(X_train, y_train)
    if lgb_model is not None:
        models['LightGBM'] = lgb_model
        scores['LightGBM'] = lgb_score

    # Create stacking ensemble
    if len(models) >= 2:
        stacking_model, stacking_score = create_stacking_ensemble(models, X_train, y_train)
        models['Stacking'] = stacking_model
        scores['Stacking'] = stacking_score

    # Compare models
    print("\n" + "="*60)
    print("Model Comparison")
    print("="*60)
    for name, score in sorted(scores.items(), key=lambda x: x[1], reverse=True):
        expected_points = max(min((score - 0.8) / 0.08, 1), 0) * 100
        print(f"{name:20s}: {score:.4f} (~{expected_points:.1f} points)")

    best_name = max(scores, key=scores.get)
    best_model = models[best_name]
    best_score = scores[best_name]

    print(f"\nðŸ† Best: {best_name} (CV ROC-AUC: {best_score:.4f})")

    # Try calibration on best model
    calibrated_model, calibrated_score = calibrate_model(best_model, X_train, y_train)
    if calibrated_score > best_score:
        print(f"âœ… Calibration improved score: {calibrated_score:.4f}")
        best_model = calibrated_model
        best_score = calibrated_score

    # Generate predictions
    print("\n" + "="*60)
    print("Generating Predictions")
    print("="*60)

    probabilities = best_model.predict_proba(X_test)[:, 1]
    print(f"Prob stats: min={probabilities.min():.4f}, max={probabilities.max():.4f}, mean={probabilities.mean():.4f}")

    # Save best single model
    output_df = pd.DataFrame({'target': probabilities})
    output_df.to_csv('answers.csv', index=False)
    print(f"âœ… Best model predictions â†’ answers.csv")

    # Create weighted ensemble of all models
    print("\nCreating weighted ensemble...")
    all_probs = []
    all_weights = []

    for name, model in models.items():
        probs = model.predict_proba(X_test)[:, 1]
        weight = scores[name]
        all_probs.append(probs * weight)
        all_weights.append(weight)
        print(f"  {name}: weight={weight:.4f}")

    ensemble_probs = np.array(all_probs).sum(axis=0) / sum(all_weights)

    ensemble_df = pd.DataFrame({'target': ensemble_probs})
    ensemble_df.to_csv('answers_ensemble.csv', index=False)
    print(f"âœ… Ensemble predictions â†’ answers_ensemble.csv")

    # Create average ensemble (unweighted)
    avg_probs = np.array([model.predict_proba(X_test)[:, 1] for model in models.values()]).mean(axis=0)
    avg_df = pd.DataFrame({'target': avg_probs})
    avg_df.to_csv('answers_avg.csv', index=False)
    print(f"âœ… Average ensemble â†’ answers_avg.csv")

    print("\n" + "="*60)
    print("Summary")
    print("="*60)
    print(f"Best single: {best_name} (CV ROC-AUC: {best_score:.4f})")
    print(f"Files: answers.csv, answers_ensemble.csv, answers_avg.csv")
    print(f"ðŸ’¡ Test all three files to find the best!")


if __name__ == "__main__":
    main()
