# üèÜ –ü–£–¢–¨ –ö 100 –ë–ê–õ–õ–ê–ú: –ß–¢–û –ü–†–ò–í–ï–õ–û –ö –£–°–ü–ï–•–£

## üìä –≠–≤–æ–ª—é—Ü–∏—è —Ä–µ—à–µ–Ω–∏—è

| –í–µ—Ä—Å–∏—è | CV AUC | Test –±–∞–ª–ª—ã | –ö–ª—é—á–µ–≤–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ | –†–µ–∑—É–ª—å—Ç–∞—Ç |
|--------|--------|------------|-------------------|-----------|
| v1 | - | 0 | –ë–∏–Ω–∞—Ä–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è | ‚ùå –ü—Ä–æ–≤–∞–ª |
| v2 | 0.870 | 64-67 | –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ | ‚úÖ –†–∞–±–æ—Ç–∞–µ—Ç |
| v3 | 0.8677 | 84 | Feature engineering + –∞–Ω—Å–∞–º–±–ª—å | ‚úÖ –•–æ—Ä–æ—à–æ |
| v4 | 0.8692 | 74 | Feature selection | ‚ùå –ü—Ä–æ–≤–∞–ª |
| v5 | 0.8809 | 94 | –°–∏–ª—å–Ω–∞—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è | ‚úÖ –û—Ç–ª–∏—á–Ω–æ |
| v6 | 0.8624 | 77 | Domain adaptation | ‚ùå –ü—Ä–æ–≤–∞–ª |
| **v5_optimized** | **0.8853** | **100** | **Optuna –≤–µ—Å–∞** | üèÜ **–£–°–ü–ï–•** |

---

## üéØ –¢—Ä–∏ –∫–ª—é—á–∞ –∫ —É—Å–ø–µ—Ö—É

### 1Ô∏è‚É£ **–°–∏–ª—å–Ω–∞—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è** (v3 ‚Üí v5: +10 –±–∞–ª–ª–æ–≤)

**–ü—Ä–æ–±–ª–µ–º–∞ v3:**
```
Train AUC: 1.0000  ‚Üê –ú–æ–¥–µ–ª—å –∑–∞–ø–æ–º–Ω–∏–ª–∞ –¥–∞–Ω–Ω—ã–µ –Ω–∞–∏–∑—É—Å—Ç—å
CV AUC:    0.8677
Gap:       0.1323  ‚Üê –ö—Ä–∏—Ç–∏—á–µ—Å–∫–æ–µ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ (> 0.12)
Test:      84 –±–∞–ª–ª–∞
```

**–†–µ—à–µ–Ω–∏–µ v5:**
```python
# –ê–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏
lgb.LGBMClassifier(
    max_depth=4,              # –ë—ã–ª–æ: 6 ‚Üí –ü—Ä–æ—Å—Ç—ã–µ –¥–µ—Ä–µ–≤—å—è
    learning_rate=0.03,       # –ë—ã–ª–æ: 0.05 ‚Üí –ú–µ–¥–ª–µ–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ
    min_child_samples=30,     # –ë—ã–ª–æ: 20 ‚Üí –ù–∞–¥–µ–∂–Ω—ã–µ –ø—Ä–∞–≤–∏–ª–∞
    reg_alpha=2.0,            # –ë—ã–ª–æ: 0.5 ‚Üí –°–∏–ª—å–Ω–∞—è L1
    reg_lambda=5.0,           # –ë—ã–ª–æ: 2.0 ‚Üí –°–∏–ª—å–Ω–∞—è L2
    subsample=0.7,            # –ë—ã–ª–æ: 0.8 ‚Üí –ú–µ–Ω—å—à–µ –¥–∞–Ω–Ω—ã—Ö
    colsample_bytree=0.7      # –ë—ã–ª–æ: 0.8 ‚Üí –ú–µ–Ω—å—à–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
)
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç v5:**
```
Train AUC: 0.9866  ‚Üê –ú–æ–¥–µ–ª—å –ø–æ–Ω—è–ª–∞ –∑–∞–∫–æ–Ω–æ–º–µ—Ä–Ω–æ—Å—Ç–∏ (–Ω–µ –∏–¥–µ–∞–ª—å–Ω–æ - —Ö–æ—Ä–æ—à–æ!)
CV AUC:    0.8809
Gap:       0.1057  ‚Üê –ü—Ä–∏–µ–º–ª–µ–º–æ–µ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ (< 0.12)
Test:      94 –±–∞–ª–ª–∞ (+10 –±–∞–ª–ª–æ–≤!)
```

**üí° –ö–ª—é—á–µ–≤–æ–π –∏–Ω—Å–∞–π—Ç:**
> Train AUC = 1.0 - —ç—Ç–æ –ü–õ–û–•–û (–∑–∞–ø–æ–º–∏–Ω–∞–Ω–∏–µ)
> Train AUC ‚âà 0.98 - —ç—Ç–æ –•–û–†–û–®–û (–æ–±—É—á–µ–Ω–∏–µ)

---

### 2Ô∏è‚É£ **–ö–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω–∞—è feature engineering** (v4 ‚Üí v5: +20 –±–∞–ª–ª–æ–≤)

**–ü—Ä–æ–≤–∞–ª v4:**
```python
# Feature selection —É–¥–∞–ª–∏–ª –≤–∞–∂–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
selector = SelectFromModel(model, threshold='median')
27 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ ‚Üí 14 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
–†–µ–∑—É–ª—å—Ç–∞—Ç: CV 0.8692 ‚Üí Test 74 –±–∞–ª–ª–∞ ‚ùå
```

**–£—Å–ø–µ—Ö v5:**
```python
# –°–æ—Ö—Ä–∞–Ω–∏–ª–∏ –≤—Å–µ –±–∞–∑–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ + –æ—Å—Ç–æ—Ä–æ–∂–Ω–∞—è –∏–Ω–∂–µ–Ω–µ—Ä–∏—è
22 –ø—Ä–∏–∑–Ω–∞–∫–∞:
  - 9 –±–∞–∑–æ–≤—ã—Ö (A-I)
  - 4 –∫–ª—é—á–µ–≤—ã—Ö –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è (A_E, A_G, A_H, G_H)
  - 3 –∫–≤–∞–¥—Ä–∞—Ç–∏—á–Ω—ã—Ö —á–ª–µ–Ω–∞ (A¬≤, G¬≤, H¬≤)
  - 2 –ª–æ–≥–∞—Ä–∏—Ñ–º–∞ (log_A, log_G)
  - 2 —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—è (A/D, G/I)
  - 1 –∞–≥—Ä–µ–≥–∞—Ç (G+H+I)
  - 1 –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä –ø—Ä–æ–ø—É—Å–∫–æ–≤ (E_missing)
```

**üí° –ö–ª—é—á–µ–≤–æ–π –∏–Ω—Å–∞–π—Ç:**
> –õ—É—á—à–µ 22 –ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–∞, —á–µ–º 31 —Å —à—É–º–æ–º
> Feature selection –º–æ–∂–µ—Ç —É–¥–∞–ª–∏—Ç—å –≤–∞–∂–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏

---

### 3Ô∏è‚É£ **–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤ –∞–Ω—Å–∞–º–±–ª—è** (v5 ‚Üí v5_optimized: +6 –±–∞–ª–ª–æ–≤)

**Baseline v5 (CV-weighted):**
```
–í–µ—Å–∞: LGB=0.202, XGB=0.200, CB=0.202, RF=0.195, GB=0.201
       ‚Üë –ü–æ—á—Ç–∏ —Ä–∞–≤–Ω—ã–µ –≤–µ—Å–∞ (–Ω–∞–∏–≤–Ω—ã–π –ø–æ–¥—Ö–æ–¥)
OOF AUC: 0.8811
Test:    94 –±–∞–ª–ª–∞
```

**Optuna optimization:**
```python
# 200 –∏—Ç–µ—Ä–∞—Ü–∏–π –ø–æ–∏—Å–∫–∞ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã—Ö –≤–µ—Å–æ–≤
study = optuna.create_study(direction='maximize')
study.optimize(objective, n_trials=200)
```

**v5_optimized (Optuna-weighted):**
```
–û–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –≤–µ—Å–∞:
  CatBoost:         0.447  ‚¨ÜÔ∏è‚¨ÜÔ∏è (–≥–ª–∞–≤–Ω–∞—è –º–æ–¥–µ–ª—å!)
  LightGBM:         0.300  ‚¨ÜÔ∏è
  GradientBoosting: 0.004  ‚¨áÔ∏è‚¨áÔ∏è (–ø–æ—á—Ç–∏ –Ω–µ –Ω—É–∂–µ–Ω)
  RandomForest:     0.025  ‚¨áÔ∏è
  XGBoost:          0.019  ‚¨áÔ∏è

OOF AUC: 0.8853 (+0.0042)
Test:    100 –±–∞–ª–ª–æ–≤ (+6 –±–∞–ª–ª–æ–≤!)
```

**üí° –ö–ª—é—á–µ–≤–æ–π –∏–Ω—Å–∞–π—Ç:**
> CatBoost –æ–∫–∞–∑–∞–ª—Å—è –ª—É—á—à–µ–π –º–æ–¥–µ–ª—å—é (45% –≤–µ—Å–∞)
> –ù–µ–∫–æ—Ç–æ—Ä—ã–µ –º–æ–¥–µ–ª–∏ (GB, RF, XGB) –ø–æ—á—Ç–∏ –Ω–µ –Ω—É–∂–Ω—ã –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –∞–Ω—Å–∞–º–±–ª—è

---

## ‚ùå –ß—Ç–æ –ù–ï —Å—Ä–∞–±–æ—Ç–∞–ª–æ –∏ –ø–æ—á–µ–º—É

### 1. Feature Selection (v4)
```
‚ùå –ü—Ä–æ–±–ª–µ–º–∞: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –æ—Ç–±–æ—Ä —É–¥–∞–ª–∏–ª –≤–∞–∂–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
   SelectFromModel —Å threshold='median' ‚Üí –ø–æ—Ç–µ—Ä—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏

‚úÖ –£—Ä–æ–∫: –õ—É—á—à–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—é, —á–µ–º —É–¥–∞–ª—è—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–∏
```

### 2. Domain Adaptation —Å –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–º re-weighting (v6)
```
‚ùå –ü—Ä–æ–±–ª–µ–º–∞: Sample weights –¥–æ 14.9x —Å–æ–∑–¥–∞–ª–∏ –Ω–æ–≤—ã–π –¥–∏—Å–±–∞–ª–∞–Ω—Å
   –ú–æ–¥–µ–ª—å –ø–µ—Ä–µ–æ–±—É—á–∏–ª–∞—Å—å –Ω–∞ –Ω–µ–±–æ–ª—å—à–æ–µ –ø–æ–¥–º–Ω–æ–∂–µ—Å—Ç–≤–æ "test-like" –ø—Ä–∏–º–µ—Ä–æ–≤
   CV 0.8624 < 0.8809 (—Ö—É–∂–µ v5)
   Test 77 –±–∞–ª–ª–æ–≤ < 94 –±–∞–ª–ª–æ–≤ (—Ö—É–∂–µ v5)

‚úÖ –£—Ä–æ–∫: –î–∞–∂–µ –ø—Ä–∏ distribution shift (Adv AUC 0.90),
         –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–∞—è –∞–¥–∞–ø—Ç–∞—Ü–∏—è –º–æ–∂–µ—Ç –Ω–∞–≤—Ä–µ–¥–∏—Ç—å
```

### 3. –°–ª–∞–±–∞—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è (v3)
```
‚ùå –ü—Ä–æ–±–ª–µ–º–∞: Train AUC = 1.0, Gap 0.1323 > 0.12
   –ú–æ–¥–µ–ª—å –∑–∞–ø–æ–º–Ω–∏–ª–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
   CV –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–ª 90 –±–∞–ª–ª–æ–≤, –ø–æ–ª—É—á–∏–ª–∏ 84

‚úÖ –£—Ä–æ–∫: Gap > 0.12 - —Å–∏–≥–Ω–∞–ª —Ç—Ä–µ–≤–æ–≥–∏
```

---

## üîç Adversarial Validation: –≤–∞–∂–Ω–æ–µ –æ—Ç–∫—Ä—ã—Ç–∏–µ

```python
# –ü—Ä–æ–≤–µ—Ä–∏–ª–∏ –ø–æ—Ö–æ–∂–µ—Å—Ç—å train –∏ test
Adversarial AUC: 0.9034  ‚Üê –û—á–µ–Ω—å –≤—ã—Å–æ–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ!
```

**–ß—Ç–æ —ç—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç:**
- Train –∏ Test –∏–∑ **—Ä–∞–∑–Ω—ã—Ö —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π**
- –ü—Ä–∏–∑–Ω–∞–∫–∏ H, I, A —Å–∏–ª—å–Ω–æ –æ—Ç–ª–∏—á–∞—é—Ç—Å—è:
  - H: train=-0.16, test=-1.06 (—Ä–∞–∑–Ω–∏—Ü–∞ 573%!)
  - I: train=1.20, test=1.71 (—Ä–∞–∑–Ω–∏—Ü–∞ 43%)
  - C: train=0.20, test=0.28 (—Ä–∞–∑–Ω–∏—Ü–∞ 38%)

**–ü–æ—á–µ–º—É —ç—Ç–æ –≤–∞–∂–Ω–æ:**
> –≠—Ç–æ –æ–±—ä—è—Å–Ω—è–µ—Ç, –ø–æ—á–µ–º—É CV –Ω–µ —Ç–æ—á–Ω–æ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–ª Test
> v3: CV 0.8677 (–æ–∂–∏–¥–∞–ª–∏ ~90) ‚Üí Test 84 (-6 –±–∞–ª–ª–æ–≤)
> v5: CV 0.8809 (–æ–∂–∏–¥–∞–ª–∏ ~100) ‚Üí Test 94 (-6 –±–∞–ª–ª–æ–≤)
> v5_optimized: CV 0.8853 (–æ–∂–∏–¥–∞–ª–∏ ~107) ‚Üí Test 100 (-7 –±–∞–ª–ª–æ–≤)

**üí° –ö–ª—é—á–µ–≤–æ–π –∏–Ω—Å–∞–π—Ç:**
> –ü—Ä–∏ distribution shift CV –ø–µ—Ä–µ–æ—Ü–µ–Ω–∏–≤–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–∞ ~6-7 –±–∞–ª–ª–æ–≤
> –≠—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ –∏ —É—á–∏—Ç—ã–≤–∞–µ—Ç—Å—è –ø—Ä–∏ –æ—Ü–µ–Ω–∫–µ –æ–∂–∏–¥–∞–Ω–∏–π

---

## üß† –§–∏–Ω–∞–ª—å–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ v5_optimized

### **–ü—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥:**
```python
1. C: '+' ‚Üí 1, '-' ‚Üí 0
2. E: fillna(median), —Å–æ–∑–¥–∞—Ç—å E_missing –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä
3. Robust scaling –ù–ï –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª—Å—è (—É—Ö—É–¥—à–∞–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ v6)
```

### **Feature Engineering (22 –ø—Ä–∏–∑–Ω–∞–∫–∞):**
```python
# –ë–∞–∑–æ–≤—ã–µ: A, B, C, D, E, F, G, H, I (9)
# –í–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è: A*E, A*G, A*H, G*H (4)
# –ü–æ–ª–∏–Ω–æ–º–∏–∞–ª—å–Ω—ã–µ: A¬≤, G¬≤, H¬≤ (3)
# –õ–æ–≥–∞—Ä–∏—Ñ–º—ã: log(A+1), log(G+10) (2)
# –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—è: A/(D+0.001), G/(|I|+1) (2)
# –ê–≥—Ä–µ–≥–∞—Ç—ã: G+H+I (1)
# –ò–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã: E_missing (1)
```

### **–ú–æ–¥–µ–ª–∏ —Å —Å–∏–ª—å–Ω–æ–π —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–µ–π:**

**LightGBM (–≤–µ—Å 30%):**
```python
n_estimators=400, max_depth=4, lr=0.03
min_child_samples=30, reg_alpha=2.0, reg_lambda=5.0
subsample=0.7, colsample_bytree=0.7
```

**XGBoost (–≤–µ—Å 1.9%):**
```python
n_estimators=400, max_depth=4, lr=0.03
min_child_weight=10, gamma=0.5
reg_alpha=2.0, reg_lambda=5.0
subsample=0.7, colsample_bytree=0.7
```

**CatBoost (–≤–µ—Å 44.7% - –ì–õ–ê–í–ù–ê–Ø –ú–û–î–ï–õ–¨):**
```python
iterations=400, depth=4, lr=0.03
l2_leaf_reg=5.0, random_strength=2.0
bagging_temperature=0.7
```

**RandomForest (–≤–µ—Å 2.5%):**
```python
n_estimators=200, max_depth=8
min_samples_split=30, min_samples_leaf=15
class_weight='balanced'
```

**GradientBoosting (–≤–µ—Å 0.4%):**
```python
n_estimators=200, max_depth=4, lr=0.03
subsample=0.7, min_samples_split=30
```

### **–ê–Ω—Å–∞–º–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ:**
```python
# Optuna –Ω–∞—à–µ–ª –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –≤–µ—Å–∞ —á–µ—Ä–µ–∑ 200 –∏—Ç–µ—Ä–∞—Ü–∏–π
final_pred = (0.447 * catboost_pred +
              0.300 * lightgbm_pred +
              0.025 * rf_pred +
              0.019 * xgboost_pred +
              0.004 * gb_pred)
```

---

## üìà –ú–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞

### **Overfit Gap (Train AUC - CV AUC):**
```
v3: 0.1323  ‚ùå –ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ
v5: 0.1057  ‚úÖ –ö–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ–º–æ–µ –æ–±—É—á–µ–Ω–∏–µ
–¶–µ–ª—å: < 0.12
```

### **Cross-Validation AUC:**
```
v3: 0.8677
v5: 0.8809 (+0.0132)
v5_optimized: 0.8853 (+0.0044)
```

### **Test Score:**
```
v3: 84 –±–∞–ª–ª–∞
v5: 94 –±–∞–ª–ª–∞ (+10)
v5_optimized: 100 –±–∞–ª–ª–æ–≤ (+6)
```

---

## üéì –ì–ª–∞–≤–Ω—ã–µ —É—Ä–æ–∫–∏

### 1. **–†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è –≤–∞–∂–Ω–µ–µ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏**
```
‚úÖ Train AUC 0.98 + CV AUC 0.88 > Train AUC 1.0 + CV AUC 0.87
   –ú–æ–¥–µ–ª—å –¥–æ–ª–∂–Ω–∞ –ü–û–ù–ò–ú–ê–¢–¨, –∞ –Ω–µ –ó–ê–ü–û–ú–ò–ù–ê–¢–¨
```

### 2. **Gap < 0.12 - –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π –ø–æ—Ä–æ–≥**
```
Gap > 0.12 ‚Üí CV –Ω–µ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç Test
Gap < 0.12 ‚Üí CV –Ω–∞–¥–µ–∂–Ω–æ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç Test
```

### 3. **–ö–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω–∞—è feature engineering**
```
‚úÖ –ü—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ + –∫–ª—é—á–µ–≤—ã–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è
‚ùå –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π feature selection –º–æ–∂–µ—Ç —É–¥–∞–ª–∏—Ç—å –≤–∞–∂–Ω–æ–µ
```

### 4. **–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤ –∞–Ω—Å–∞–º–±–ª—è –¥–∞–µ—Ç –±—É—Å—Ç**
```
–†–∞–≤–Ω—ã–µ –≤–µ—Å–∞ ‚Üí Optuna: +6 –±–∞–ª–ª–æ–≤
CatBoost –æ–∫–∞–∑–∞–ª—Å—è –ª—É—á—à–µ–π –º–æ–¥–µ–ª—å—é (45% –≤–µ—Å–∞)
```

### 5. **Distribution shift - —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ**
```
Adversarial AUC 0.90 ‚Üí CV –ø–µ—Ä–µ–æ—Ü–µ–Ω–∏–≤–∞–µ—Ç –Ω–∞ ~6-7 –±–∞–ª–ª–æ–≤
–ê–≥—Ä–µ—Å—Å–∏–≤–Ω–∞—è domain adaptation –º–æ–∂–µ—Ç –Ω–∞–≤—Ä–µ–¥–∏—Ç—å
```

### 6. **–ü—Ä–æ—Å—Ç–æ—Ç–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç**
```
v5_optimized:
  - 22 –ø—Ä–∏–∑–Ω–∞–∫–∞ (–Ω–µ 31)
  - 5 –º–æ–¥–µ–ª–µ–π —Å —Å–∏–ª—å–Ω–æ–π —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–µ–π
  - Optuna –¥–ª—è –≤–µ—Å–æ–≤
  - –ù–∏–∫–∞–∫–∏—Ö —ç–∫–∑–æ—Ç–∏—á–µ—Å–∫–∏—Ö —Ç–µ—Ö–Ω–∏–∫

–†–µ–∑—É–ª—å—Ç–∞—Ç: 100 –±–∞–ª–ª–æ–≤
```

---

## üõ†Ô∏è –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π —Å—Ç–µ–∫

```
–Ø–∑—ã–∫:          Python 3.x
ML-–±–∏–±–ª–∏–æ—Ç–µ–∫–∏: LightGBM, XGBoost, CatBoost, scikit-learn
–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è:   Optuna (TPE sampler)
–í–∞–ª–∏–¥–∞—Ü–∏—è:     StratifiedKFold (5 folds)
–ú–µ—Ç—Ä–∏–∫–∞:       ROC-AUC
```

---

## üìä –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞

```
Dataset:
  Train: 1000 samples, 9 features
  Test:  500 samples
  Class imbalance: 71.2% / 28.8%
  Missing values: ~75 –≤ –ø—Ä–∏–∑–Ω–∞–∫–µ E

–§–∏–Ω–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å:
  Features: 22 (–∏–Ω–∂–µ–Ω–µ—Ä–∏—è)
  Models: 5 (—Å–∏–ª—å–Ω–∞—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è)
  Ensemble: Optuna-weighted average

  CV AUC:  0.8853
  Gap:     0.1057 (< 0.12 ‚úÖ)
  Test:    100 –±–∞–ª–ª–æ–≤ üèÜ
```

---

## üéØ –§–æ—Ä–º—É–ª–∞ —É—Å–ø–µ—Ö–∞

```
–£–°–ü–ï–• = –°–∏–ª—å–Ω–∞—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è
      + –ö–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω–∞—è feature engineering
      + –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤ –∞–Ω—Å–∞–º–±–ª—è
      - Feature selection
      - –ê–≥—Ä–µ—Å—Å–∏–≤–Ω–∞—è domain adaptation
```

**–í—Ä–µ–º—è –¥–æ —Ä–µ—à–µ–Ω–∏—è:** ~7 –∏—Ç–µ—Ä–∞—Ü–∏–π
**–ö–ª—é—á–µ–≤–æ–π –ø—Ä–æ—Ä—ã–≤:** –ü–æ–Ω–∏–º–∞–Ω–∏–µ –≤–∞–∂–Ω–æ—Å—Ç–∏ Gap < 0.12
**–§–∏–Ω–∞–ª—å–Ω—ã–π –±—É—Å—Ç:** Optuna optimization (+6 –±–∞–ª–ª–æ–≤)

---

## üöÄ –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏ (–µ—Å–ª–∏ –±—ã –Ω—É–∂–Ω–æ –±—ã–ª–æ —É–ª—É—á—à–∏—Ç—å –µ—â—ë)

1. **Stacking meta-learner** (v7 –≥–æ—Ç–æ–≤)
   - –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª: +1-3 –±–∞–ª–ª–∞
   - –ò—Å–ø–æ–ª—å–∑—É–µ—Ç OOF –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∫–∞–∫ –ø—Ä–∏–∑–Ω–∞–∫–∏

2. **Ensemble averaging —Å —Ä–∞–∑–Ω—ã–º–∏ seeds**
   - –û–±—É—á–∏—Ç—å –∫–∞–∂–¥—É—é –º–æ–¥–µ–ª—å 3-5 —Ä–∞–∑
   - –£—Å—Ä–µ–¥–Ω–∏—Ç—å –¥–ª—è —Å–Ω–∏–∂–µ–Ω–∏—è variance
   - –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª: +1-2 –±–∞–ª–ª–∞

3. **Advanced feature engineering**
   - Target encoding
   - Percentile features
   - Higher-order interactions
   - –†–∏—Å–∫: –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ

4. **Pseudo-labeling**
   - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —É–≤–µ—Ä–µ–Ω–Ω—ã–µ test –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
   - –î–æ–±–∞–≤–∏—Ç—å –≤ train –∏ –ø–µ—Ä–µ–æ–±—É—á–∏—Ç—å
   - –†–∏—Å–∫: propagation of errors

**–ù–û:** 100 –±–∞–ª–ª–æ–≤ —É–∂–µ –¥–æ—Å—Ç–∏–≥–Ω—É—Ç–æ! üéâ

---

## üíæ –§–∞–π–ª—ã —Ä–µ—à–µ–Ω–∏—è

```
–§–∏–Ω–∞–ª—å–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ:
  üìÑ classifier_v5.py          - –ú–æ–¥–µ–ª—å —Å —Å–∏–ª—å–Ω–æ–π —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–µ–π
  üìÑ optimize_v5_weights.py    - Optuna –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤
  üìÑ answers_v5_optimized.csv  - 100 –±–∞–ª–ª–æ–≤! üèÜ

–ê–Ω–∞–ª–∏–∑:
  üìÑ adversarial_validation.py - Distribution shift –∞–Ω–∞–ª–∏–∑
  üìÑ explain_gap.py            - –ü–æ—á–µ–º—É gap 0.13 - —ç—Ç–æ –º–Ω–æ–≥–æ
  üìÑ visualize_regularization.py - –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏
  üìÑ compare_versions.py       - –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –≤–µ—Ä—Å–∏–π

–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è:
  üìÑ regularization_summary.md - –û–±—ä—è—Å–Ω–µ–Ω–∏–µ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏
  üìÑ gap_summary.txt           - –ö—Ä–∞—Ç–∫–∏–π guide –ø–æ gap
  üìÑ SUCCESS_SUMMARY.md        - –≠—Ç–æ—Ç –¥–æ–∫—É–º–µ–Ω—Ç
```

---

## üèÜ –í—ã–≤–æ–¥

**100 –±–∞–ª–ª–æ–≤ –¥–æ—Å—Ç–∏–≥–Ω—É—Ç–æ –±–ª–∞–≥–æ–¥–∞—Ä—è:**

1. ‚úÖ **–°–∏–ª—å–Ω–æ–π —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏** (max_depth=4, reg_alpha=2.0, reg_lambda=5.0)
2. ‚úÖ **–ö–æ–Ω—Ç—Ä–æ–ª—é –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è** (Gap 0.1057 < 0.12)
3. ‚úÖ **–ö–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω–æ–π feature engineering** (22 –ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–∞)
4. ‚úÖ **–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –≤–µ—Å–æ–≤ –∞–Ω—Å–∞–º–±–ª—è** (Optuna: CatBoost 45%, LightGBM 30%)
5. ‚úÖ **–ò–∑–±–µ–≥–∞–Ω–∏—é –ª–æ–≤—É—à–µ–∫** (feature selection, –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–∞—è domain adaptation)

**–ö–ª—é—á–µ–≤–æ–π –ø—Ä–∏–Ω—Ü–∏–ø:**
> –ü—Ä–æ—Å—Ç–æ—Ç–∞ + –†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è + –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è > –°–ª–æ–∂–Ω–æ—Å—Ç—å

---

**–ü–æ–∑–¥—Ä–∞–≤–ª—è—é —Å —É—Å–ø–µ—Ö–æ–º! üéâ**
